{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paracetamol/acetaminophen is one of the most popular and most commonly used analgesic and antipyretic drugs around the world, available without a prescription, both in mono- and multi-component preparations. It is the drug of choice in patients that cannot be treated with non-steroidal anti-inflammatory drugs (NSAID), such as people with bronchial asthma, peptic ulcer disease, hemophilia, salicylate-sensitized people, children under 12 years of age, pregnant or breastfeeding women. It is recommended as a first-line treatment of pain associated with osteoarthritis. The mechanism of action is complex and includes the effects of both the peripheral (COX inhibition), and central (COX, serotonergic descending neuronal pathway, L-arginine/NO pathway, cannabinoid system) antinociception processes and \"redox\" mechanism. Paracetamol is well tolerated drug and produces few side effects from the gastrointestinal tract, however, despite that, every year, has seen a steadily increasing number of registered cases of paracetamol-induced liver intoxication all over the world. Given the growing problem of the safety of acetaminophen is questioned the validity of the sale of the drug without a prescription. This work, in conjunction with the latest reports on the mechanism of action of paracetamol, trying to point out that it is not a panacea devoid of side effects, and indeed, especially when is taken regularly and in large doses (> 4 g/day), there is a risk of serious side effects.\n"
     ]
    }
   ],
   "source": [
    "with open ('main_data/para.txt', 'r') as f:\n",
    "    texts = f.read()\n",
    "    print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\learn_django\\tryagain\\DATA_FIXING\\hugging_face_LC.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext_splitter\u001b[39;00m \u001b[39mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m text_splitter \u001b[39m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     chunk_size \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     chunk_overlap  \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     length_function \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m texts \u001b[39m=\u001b[39m text_splitter\u001b[39m.\u001b[39;49msplit_documents(texts)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(texts))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(texts[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\langchain\\text_splitter.py:129\u001b[0m, in \u001b[0;36mTextSplitter.split_documents\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m    127\u001b[0m texts, metadatas \u001b[39m=\u001b[39m [], []\n\u001b[0;32m    128\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents:\n\u001b[1;32m--> 129\u001b[0m     texts\u001b[39m.\u001b[39mappend(doc\u001b[39m.\u001b[39;49mpage_content)\n\u001b[0;32m    130\u001b[0m     metadatas\u001b[39m.\u001b[39mappend(doc\u001b[39m.\u001b[39mmetadata)\n\u001b[0;32m    131\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_documents(texts, metadatas\u001b[39m=\u001b[39mmetadatas)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_documents(texts)\n",
    "print(len(texts))\n",
    "print(texts[0])\n",
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)7d923/.gitattributes: 100%|██████████| 1.48k/1.48k [00:00<00:00, 736kB/s]\n",
      "Downloading (…)99bee7d923/README.md: 100%|██████████| 5.92k/5.92k [00:00<00:00, 2.96MB/s]\n",
      "Downloading (…)bee7d923/config.json: 100%|██████████| 595/595 [00:00<00:00, 207kB/s]\n",
      "Downloading (…)9bee7d923/merges.txt: 100%|██████████| 696k/696k [00:00<00:00, 825kB/s]\n",
      "Downloading pytorch_model.bin:  52%|█████▏    | 807M/1.56G [01:33<01:35, 7.90MB/s] "
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\urllib3\\response.py:444\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n\u001b[0;32m    447\u001b[0m     \u001b[39m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     \u001b[39m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\urllib3\\response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 567\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\urllib3\\response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\http\\client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    458\u001b[0m b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 459\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[0;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\http\\client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 503\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[0;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[0;32m    505\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    506\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 669\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    670\u001b[0m \u001b[39mexcept\u001b[39;00m timeout:\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1100\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mtimeout\u001b[0m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\urllib3\\response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[1;32m--> 628\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[0;32m    630\u001b[0m     \u001b[39mif\u001b[39;00m data:\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\urllib3\\response.py:593\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    584\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menforce_content_length \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength_remaining \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\n\u001b[0;32m    585\u001b[0m                 \u001b[39m0\u001b[39m,\n\u001b[0;32m    586\u001b[0m                 \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[39m# raised during streaming, so all calls with incorrect\u001b[39;00m\n\u001b[0;32m    592\u001b[0m                 \u001b[39m# Content-Length are caught.\u001b[39;00m\n\u001b[1;32m--> 593\u001b[0m                 \u001b[39mraise\u001b[39;00m IncompleteRead(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp_bytes_read, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength_remaining)\n\u001b[0;32m    595\u001b[0m \u001b[39mif\u001b[39;00m data:\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\contextlib.py:131\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(\u001b[39mtype\u001b[39;49m, value, traceback)\n\u001b[0;32m    132\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    133\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\urllib3\\response.py:449\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n\u001b[0;32m    447\u001b[0m     \u001b[39m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     \u001b[39m# there is yet no clean way to get at it from this context.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m     \u001b[39mraise\u001b[39;00m ReadTimeoutError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool, \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mRead timed out.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    451\u001b[0m \u001b[39mexcept\u001b[39;00m BaseSSLError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    452\u001b[0m     \u001b[39m# FIXME: Is there a better way to differentiate between SSLErrors?\u001b[39;00m\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32md:\\learn_django\\tryagain\\DATA_FIXING\\hugging_face_LC.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model_id \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmicrosoft/biogpt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model_kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m hf_embedding \u001b[39m=\u001b[39m HuggingFaceEmbeddings(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     model_name\u001b[39m=\u001b[39;49mmodel_id,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     model_kwargs\u001b[39m=\u001b[39;49mmodel_kwargs\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m db \u001b[39m=\u001b[39m DocArrayInMemorySearch\u001b[39m.\u001b[39mfrom_texts(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     texts,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     hf_embedding\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/learn_django/tryagain/DATA_FIXING/hugging_face_LC.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\langchain\\embeddings\\huggingface.py:58\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     53\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     54\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import sentence_transformers python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     55\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install sentence_transformers`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient \u001b[39m=\u001b[39m sentence_transformers\u001b[39m.\u001b[39;49mSentenceTransformer(\n\u001b[0;32m     59\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_name, cache_folder\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_folder, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_kwargs\n\u001b[0;32m     60\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:87\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[0;32m     83\u001b[0m     model_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(cache_folder, model_name_or_path\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_path, \u001b[39m'\u001b[39m\u001b[39mmodules.json\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m     86\u001b[0m         \u001b[39m# Download from hub with caching\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m         snapshot_download(model_name_or_path,\n\u001b[0;32m     88\u001b[0m                             cache_dir\u001b[39m=\u001b[39;49mcache_folder,\n\u001b[0;32m     89\u001b[0m                             library_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msentence-transformers\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     90\u001b[0m                             library_version\u001b[39m=\u001b[39;49m__version__,\n\u001b[0;32m     91\u001b[0m                             ignore_files\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mflax_model.msgpack\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrust_model.ot\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtf_model.h5\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m     92\u001b[0m                             use_auth_token\u001b[39m=\u001b[39;49muse_auth_token)\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_path, \u001b[39m'\u001b[39m\u001b[39mmodules.json\u001b[39m\u001b[39m'\u001b[39m)):    \u001b[39m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     modules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_sbert_model(model_path)\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\sentence_transformers\\util.py:491\u001b[0m, in \u001b[0;36msnapshot_download\u001b[1;34m(repo_id, revision, cache_dir, library_name, library_version, user_agent, ignore_files, use_auth_token)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[39mif\u001b[39;00m version\u001b[39m.\u001b[39mparse(huggingface_hub\u001b[39m.\u001b[39m__version__) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m version\u001b[39m.\u001b[39mparse(\u001b[39m\"\u001b[39m\u001b[39m0.8.1\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    487\u001b[0m     \u001b[39m# huggingface_hub v0.8.1 introduces a new cache layout. We sill use a manual layout\u001b[39;00m\n\u001b[0;32m    488\u001b[0m     \u001b[39m# And need to pass legacy_cache_layout=True to avoid that a warning will be printed\u001b[39;00m\n\u001b[0;32m    489\u001b[0m     cached_download_args[\u001b[39m'\u001b[39m\u001b[39mlegacy_cache_layout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 491\u001b[0m path \u001b[39m=\u001b[39m cached_download(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcached_download_args)\n\u001b[0;32m    493\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.lock\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    494\u001b[0m     os\u001b[39m.\u001b[39mremove(path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.lock\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:800\u001b[0m, in \u001b[0;36mcached_download\u001b[1;34m(url, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[39mwith\u001b[39;00m temp_file_manager() \u001b[39mas\u001b[39;00m temp_file:\n\u001b[0;32m    798\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mdownloading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url, temp_file\u001b[39m.\u001b[39mname)\n\u001b[1;32m--> 800\u001b[0m     http_get(\n\u001b[0;32m    801\u001b[0m         url_to_download,\n\u001b[0;32m    802\u001b[0m         temp_file,\n\u001b[0;32m    803\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    804\u001b[0m         resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[0;32m    805\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    806\u001b[0m         expected_size\u001b[39m=\u001b[39;49mexpected_size,\n\u001b[0;32m    807\u001b[0m     )\n\u001b[0;32m    809\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mstoring \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url, cache_path)\n\u001b[0;32m    810\u001b[0m _chmod_and_replace(temp_file\u001b[39m.\u001b[39mname, cache_path)\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:541\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[0;32m    531\u001b[0m     displayed_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(…)\u001b[39m\u001b[39m{\u001b[39;00mdisplayed_name[\u001b[39m-\u001b[39m\u001b[39m20\u001b[39m:]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m progress \u001b[39m=\u001b[39m tqdm(\n\u001b[0;32m    534\u001b[0m     unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    535\u001b[0m     unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    539\u001b[0m     disable\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m(logger\u001b[39m.\u001b[39mgetEffectiveLevel() \u001b[39m==\u001b[39m logging\u001b[39m.\u001b[39mNOTSET),\n\u001b[0;32m    540\u001b[0m )\n\u001b[1;32m--> 541\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m):\n\u001b[0;32m    542\u001b[0m     \u001b[39mif\u001b[39;00m chunk:  \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    543\u001b[0m         progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n",
      "File \u001b[1;32mc:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\requests\\models.py:822\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[39mraise\u001b[39;00m ContentDecodingError(e)\n\u001b[0;32m    821\u001b[0m \u001b[39mexcept\u001b[39;00m ReadTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 822\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e)\n\u001b[0;32m    823\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    824\u001b[0m     \u001b[39mraise\u001b[39;00m RequestsSSLError(e)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin:  52%|█████▏    | 807M/1.56G [01:44<01:35, 7.90MB/s]"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "model_id = 'microsoft/biogpt'\n",
    "model_kwargs = {'device': 'gpu'}\n",
    "hf_embedding = HuggingFaceEmbeddings(\n",
    "    model_name=model_id,\n",
    "    model_kwargs=model_kwargs\n",
    ")\n",
    "db = DocArrayInMemorySearch.from_texts(\n",
    "    texts,\n",
    "    hf_embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='m', metadata={}), Document(page_content='m', metadata={}), Document(page_content='m', metadata={}), Document(page_content='m', metadata={})]\n"
     ]
    }
   ],
   "source": [
    "docs = db.similarity_search(\"what are ?\")\n",
    "print(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
