{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label for class admiration: 0.0029\n",
      "Predicted Label for class amusement: 0.0019\n",
      "Predicted Label for class anger: 0.0005\n",
      "Predicted Label for class annoyance: 0.0012\n",
      "Predicted Label for class approval: 0.0087\n",
      "Predicted Label for class caring: 0.0044\n",
      "Predicted Label for class confusion: 0.0417\n",
      "Predicted Label for class curiosity: 0.0021\n",
      "Predicted Label for class desire: 0.0012\n",
      "Predicted Label for class disappointment: 0.0012\n",
      "Predicted Label for class disapproval: 0.0021\n",
      "Predicted Label for class disgust: 0.0001\n",
      "Predicted Label for class embarrassment: 0.0005\n",
      "Predicted Label for class excitement: 0.0084\n",
      "Predicted Label for class fear: 0.0010\n",
      "Predicted Label for class gratitude: 0.0041\n",
      "Predicted Label for class grief: 0.0004\n",
      "Predicted Label for class joy: 0.8775\n",
      "Predicted Label for class love: 0.0032\n",
      "Predicted Label for class nervousness: 0.0032\n",
      "Predicted Label for class optimism: 0.0112\n",
      "Predicted Label for class pride: 0.0013\n",
      "Predicted Label for class realization: 0.0053\n",
      "Predicted Label for class relief: 0.0088\n",
      "Predicted Label for class remorse: 0.0008\n",
      "Predicted Label for class sadness: 0.0010\n",
      "Predicted Label for class surprise: 0.0018\n",
      "Predicted Label for class neutral: 0.0033\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
    "\n",
    "# Prepare input text\n",
    "input_text = \"I feel really happy right now, but i do not know how long it will stay.\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Move to GPU (if available)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "inputs.to(device)\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits\n",
    "\n",
    "# Interpret Results\n",
    "probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "label_list = []\n",
    "# Print predicted labels and probabilities for each class\n",
    "for i, label_id in enumerate(probabilities[0]):\n",
    "    label = model.config.id2label[i]\n",
    "    print(f\"Predicted Label for class {label}: {label_id:.4f}\")\n",
    "    label_list.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.0846, -4.4182, -5.7450, -4.9193, -2.9495, -3.6064, -1.2553, -4.2981,\n",
       "         -4.8201, -4.8448, -4.3222, -7.1218, -5.8559, -2.9087, -5.0093, -3.7118,\n",
       "         -5.9872,  1.6639, -3.8427, -3.8849, -2.6573, -4.8181, -3.3895, -2.9437,\n",
       "         -5.3321, -5.0674, -4.4519, -3.8701]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
